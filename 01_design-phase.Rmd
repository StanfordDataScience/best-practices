---
output:
  bookdown::gitbook:
    lib_dir: book_assets
---

# Study design phase

It is always exciting to start a new research project. By the time you actually roll-up your sleeves and get your hands dirty, you have probably been pondering on many things that related to your new project: what kind of questions would I like to answer? How should I formalize the question? How do I get to the answer? Should I conduct an experiment to gather some data, or should I explore the existing datasets? What does the data look like anyway? How do I make sure my answer is not wildly wrong?.... 
Then you find yourself buried in those questions, do not know where to start… Well, firstly, you are definitely on the right track thinking about all those questions! Congratulations, you just have just taken the first step! Secondly, do not be intimidated by this big fuzzy ball of thoughts. You may not know where to start, how to start, or whether you have thoroughly considered everything to start your research project. This is totally normal! I am here to propose a general framework to get your work started. Let’s call it “the research project starter kit”!
In the following four chapters, I will be introducing concepts, tools, and easy-to-follow frameworks as part of this precious starter kit. I will also share insights on study designs from experienced researchers in different scientific fields. Chapter 1 will discuss how to define the research question, a clear and effective one that we can actually act upon. Chapter 2 will introduce study designs techniques that can answer the research question effectively. Chapter 3  will touch on how to create a realistic analytical plan. Finally, Chapter 4 will provide tools for documenting all the research planning steps.
[add a paragraph] How does the best practice relate to open science? Without well planned study design, open science might be simply infeasible.. Cannot go back in time to retrieve all the missing information… for example...


## Define the research question

### Start with a question in mind.

A well-defined research question reflects the researcher’s careful thinking of the problem that he/she/they is trying to tackle. Specifying a good research question also serves the researcher a long way:

- Provides clear aims of what to achieve through the study
- Sets reasonable expectations and future goals
- Helps select appropriate methodology moving forward
- Gives a better chance to practice open science 
- What else can you think of ?... 

At this point, you may think, “oh, come on, man! A seasoned researcher like me, of course, knows how to come up with a good research question!” Well, I would say, “Man, think twice!” So what does a well-defined research question look like anyway?  To answer this question, we shall consider the following two aspects:  scientific contribution to the field and operational feasibility. 

To evaluate the scientific contribution: 
- Does the question have a solid scientific base? 
- Is the question novel?
- If the question is sufficiently answered, what will it add to the current knowledge?
- …

To evaluate the operational feasibility: 
- What is the study unit to answer the question? (Individuals? Microbial - colonies? Countries? Planet or celestial systems?
- Does the question include an explicit intervention / treatment / exposure? 
- Does the question imply a comparison group?
- Is there an anticipated outcome?
- …

**Note:** Since academic fields vary, it does not mean that your question has to fulfill all these points mentioned above. However, we do encourage you to go through these questions while you are contemplating the research question. 
[Add figure number]

```{r pressure, echo=FALSE, fig.cap="Figure credit: https://simplystatistics.org/2019/04/17/tukey-design-thinking-and-better-questions/", out.width = '100%'}

knitr::include_graphics("images/phase-1_quality-of-question.png")

```


### Classification of different questions

Another helpful practice is to carefully scrutinize what kind of question you are asking. It does not mean that some types of questions are absolutely superior to the others. The purpose of thinking through the type of the question allows us to be true to ourselves and honest to our audience when we are making any inferences from our research. Now I will go through two general classifications of reserved questions.


**Confirmatory v.s Exploratory**
- Confirmatory questions typically involve a set of hypotheses, a null hypothesis with one or more alternatives. It often requires the researcher to develop a concrete research design to test these hypotheses. The question is often answered via inductive inference. Such inference is often considered as “strong inference”, and is deemed to make a “scientific step forward”. (Platt 1964) Some examples of confirmatory questions include… add examples!  add reading on inductive and deductive reasoning (maybe the one from Steve’s class)

- Exploratory questions, unlike confirmatory questions, are not explicitly hypothesis driven. Rather, these questions are often considered to be hypotheses-generating. Hence, exploratory questions do not mean to achieve “strong inference”. Results from exploratory research cannot be over-interpreted as something confirmatory, and often yield a higher false positive rate. However, exploratory questions are meaningful and necessary for new discoveries and unexplored topics. Before we make any “strong inference”, we should always attempt to validate the results from exploratory research in a confirmatory setting. Some examples of exploratory questions include… add examples!

In summary, after you carefully think through your research question, it will be more clear to see whether your question is rather hypothesis driven or hypothesis generating. Either way may make interesting research topics, as long as you are making the right amount of inference from the results. Please be true to yourself as the Knights of the Round Table to King Arthur! When you ask an exploratory question, please do not pretend it is confirmatory no matter how hard you want to believe it is confirmatory. When you think you are asking a confirmatory question, make sure it is really confirmatory, not an exploratory question with fancy confirmatory wordings. Believe me, your reviewers will be able to tell!     


**2.2 Causal v.s Non-Causal**

Another lens of classifying the research question is to examine whether the question is trying to draw a conclusion about a causal relationship between the indexed exposures and outcomes. As a typical graduate student conducting research, I often find myself either busy establishing an association, or busy determining whether the association I find involves a cause and its effect on the outcome. Although even the famous American writer John Barth once said “The world is richer in associations than meanings, and it is the part of wisdom to differentiate the two.”, this is rather a post-hoc strategy. As having been stressed multiple times, forward thinking is really the key to high quality research. When you have a research question in mind, while thinking about how brilliant your idea is, please also go through the following items to see whether your question is causal or not. The typical causal question includes the following components:

- A well defined cause (what can be qualified as a cause? Still debatable, expand) 
- A well defined outcome 
- A scientifically plausible effect on the outcome that can be attributable to the cause
- Provide a better list of components

Moreover, English epidemiologist and statistician Austin Bradford Hill carefully summarized the common characteristics of causal relationship in his paper [The Environment and Disease: Association or Causation?](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1898525/?page=1 in 1965. Although this paper later was referred to as the “Hill Causal Criteria”, Hill himself actually suggested that we should take all these characteristics with a grain of salt. Most of the causal questions contain the “C” word ( C for cause) or the “W” word (W for why). However, a lot of times, causal questions does not explicitly contain the word “cause”, rather, it describes the effect that one factor A has on another factor B. For example: 

- What causes urban residential segregation?
- Why are rural people more politically conservative than urban people in the - United States? 
- How effective hydroxychloroquine is in treating COVID-19 patients? 
- How does the concentration of silver nitrate affect the formation of silver crystals?
- ...

The two typical classes of non-causal questions we encounter are descriptive questions and observational/associational questions. The former primarily describes the objective existence of certain phenomena. (e.g what is the ductility of bronze, silver, gold?) The latter concerns the relationship between two factors without considering the underlying causal mechanisms. (e.g how does metal ductility relate to its melting point?)

Design an infographic guide for people to go through confirmatory / exploratory and causal / non-causal questions.

**Note:** The takeaway here is that knowing the type of questions that you are asking comes quite handy when determining the downstream analytical methodology and guarding the proper inference! 


### Not All Research Questions Are Hypotheses

_“Every Science begins as philosophy and ends as art; it arises in hypothesis and flows into achievement.”_
_Will Durant_

This section, I would like to further emphasize the characteristics of research hypotheses, as they are the driving force for confirmatory studies and oftentimes the “products” of exploratory studies. As mentioned previously, research questions, as a more general concept, can take on myriad forms with fewer requirements and restrictions; whereas hypotheses, as a subset of research questions, are often phrased in a more specific way with at least one priori belief and one or more alternative(s). It usually does not take on a question form, rather it is a statement, an educated, testable prediction about the results. The main criteria of a good research hypothesis include:

- Written in clear and simple language that clearly defines both the dependent - and independent variables. 
- States the priori belief of the relationship between the dependent and - independent variables.
- Variables are defined without scientific ambiguity and are feasible to measure - using either a quantitative or qualitative approach.
- The hypothesis must be testable using scientific methods. (While constructing - the hypothesis, one shall try to think of different methods that might be - applicable to test your hypothesis.)
- The hypothesis is also feasible with respect to the current resources and time - frame.
- ...

Here are some examples of  hypotheses:

- Farmed salmon in Norway is more likely to have a higher prevalence of parasitic diseases than the wild salmon. (Good!)
  - My comment: The dependent variable is the prevalence of parasitic diseases. Independent variable is the status of farmed or wild. The predicted effect here is farmed salmon - higher prevalence of parasitic disease. Here the effect is prevalence, which is unambiguous. This is reasonably straightforward to test as well. 

- The extinction of honey will lead to mass extinction to other species, including humans. (Poor!) 
    - Now you try to apply the main criteria of a good hypothesis to critique this hypothesis, why does it sound plausible, yet is such a poor hypothesis?

Some fields have their own guidelines on how to generate “tight” hypotheses. For example, [the P.I.C.O framework](http://users.umiacs.umd.edu/~jimmylin/publications/Huang_etal_AMIA2006.pdf) is commonly used in evidence based medicine to formulate high quality clinical questions. The following table summarizes each P.I.C.O component. Although this framework is designed for one particular field, it could be applicable to other scientific disciplines as well. If your research question can be formulated in such a comparison setting, please think through these four components.

```{r, echo=FALSE, message=FALSE}
# Import
pico <- readr::read_csv(file = "tables/phase-1_pico.csv")

# Print
knitr::kable(
  x = pico,
  booktabs = T,
  caption = "The PICO framework"
)
```


_**Protip:** Use study reporting guidelines to navigate your research question formulation process.  When starting a new research project, despite our enthusiasm and motivation, we may still feel quite clueless, especially for us young researchers. Firstly, if you feel this way, fear no more, you are not alone. Secondly, there might be some good news for you. Depending on your study design (coming up in the next chapter), there are corresponding protocols to guide researchers through the study reporting phase. These reporting protocols provide a list of necessary information needed to ensure the transparency of the reported study. These reporting protocols are often developed by a panel of experts within the research field. They can be used to spur high-quality research question/hypothesis generating even at the early stage of a study! Here are several examples of such reporting guidelines:_

- _[Consolidated Standards of Reporting Trials (CONSORT)](http://www.consort-statement.org/) for randomized controlled trials_
- _[Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)](http://www.prisma-statement.org/) for systematic reviews and meta-analyses_
- _[Strengthening the Reporting of Observational Studies in Epidemiology (STROBE)](https://www.strobe-statement.org/index.php?id=strobe-home) for observational studies, such as cohort, case-control, and cross-sectional studies, and conference abstracts for these studies_
- _[Case Report Guidelines (CARE)](https://www.care-statement.org/) for case reports_
- _[Consolidated Criteria for Reporting Qualitative Research (CPREQ)](https://academic.oup.com/intqhc/article/19/6/349/1791966) for qualitative research_
- _[Animal Research: Reporting of In Vivo Experiments Guidelines (ARRIVE)](https://arriveguidelines.org/) for research involving experient animals_
- _[Consolidated Health Economic Evaluation Reporting Standards (CHEERS)](https://www.ispor.org/heor-resources/good-practices-for-outcomes-research/article/consolidated-health-economic-evaluation-reporting-standards-(cheers)---explanation-and-elaboration) for economic evaluations_

_**Protip:** Conduct literature review prior to formulate or finalize the research question or hypothesis. In Star Trek Voyager, captain Janeway led her crew to explore the uncharted delta quadrant. (They came from the alpha quadrant.) One obvious reason that they constantly got into trouble (so the show could last for seven seasons) was that they lacked the knowledge of all the planets and new alien species they were dealing with. They called them explorers. And their trip back home was full of treacherous adventures. Trust me, my friend, you don’t want your research to be anything like an adventure! Sufficient literature review prior to formulating or finalizing your research question / hypothesis will provide you a map of the scientific field that you are interested in exploring. [Provide resources on teaching literature review.]_ 


### Thinking Forward v.s Thinking Backward 
_“By failing to prepare, you are preparing to fail.”_
_Benjamin Franklin_

By now, you may have noticed that the main idea we would like to drive home is “Think ahead of time! Plan ahead of time! Prepare ahead of time! ”. Forward thinking in research conduct allows the researchers not only to better define and understand the research topics themselves, but also anticipate potential contingencies and prepare to tackle the expected “unexpected”. 

Backward thinking in scientific research is not uncommon. Think about the following scenario: you worked hard to generate some seemingly meaningful results. Because you didn’t form any plausible research question, and you were too lazy to conduct a literature review, now you do not know how to interpret the results. “Hey, it’s not too late to start some literature review!”, you said to yourself. Then you put the results in the google search bar and added a question mark in the end. Then you naively think “Voila, problem solved!”. You continued on writing the discussion section of your paper… Please don’t feel ashamed if this situation sounds quite familiar to you, however, you must know by now that this kind of practice is just horrible, period! Backward thinking often leads to HARKing, which stands for Hypothesis After Result is Known. HARKing commonly increases the risk of type I error, and further leads to reproducibility crisis. ([Click this Link to Read more about HARKing.](https://journals.sagepub.com/doi/abs/10.1207/s15327957pspr0203_4))


### Fun Readings and Additional Resources
- [Tukey, Design Thinking, and Better Questions](https://simplystatistics.org/2019/04/17/tukey-design-thinking-and-better-questions/) - a neat blog article on research questions written by [Roger Peng](http://www.biostat.jhsph.edu/~rpeng/) from Johns Hopkins University.
- ...


Add another small section on generalizability?
